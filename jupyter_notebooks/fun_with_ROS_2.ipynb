{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Robot fun with ROS 2\n",
    "\n",
    "**Igor Zubrycki**: [@IgorZub](https://twitter.com/IgorZub)\n",
    "![LUT](https://robotyka.p.lodz.pl/sites/all/themes/custom/robotyka/logo.png)\n",
    "![Marketlab](images/sygnet-m-purple.png)\n",
    "\n",
    "Slides and repo: https://github.com/AdoHaha/ros_fun\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# My goal: encourage you to start playing with robots using ROS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Robots are fun to watch and fun to play. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML, IFrame\n",
    "IFrame(\"https://www.youtube.com/embed/FM3FzZ81KOU\",560,315)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "IFrame(width=\"560\", height=\"315\", src=\"https://www.youtube.com/embed/D8_VmWWRJgE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "IFrame(width=\"560\", height=\"315\", src=\"https://www.youtube.com/embed/LfRwhA2H9fw\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What are robots, anyway?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Motion + Intelligence\n",
    "\n",
    "You want the robot to be able to create complicated behaviors and be able to realize them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# It is quite complicated in practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Rescue robotics or rescuing robots?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "IFrame(width=\"560\", height=\"315\", src=\"https://www.youtube.com/embed/g0TaYhjpOfo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![Micromouse](images/micromouse.jpg)\n",
    "\n",
    "Cool to start but quite limited -- sensors? AI? connectivity? path planning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Turtlebot burger](images/turtlebot-burger.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![\"Interdisciplinary field\"](images/robotics.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Is it even possible then?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Yes, and the answer is ROS (2) ;)\n",
    "\n",
    "![ROS2 foxy](images/foxy-small.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# ROS - Robot Operating System gives you:\n",
    "\n",
    " - ### tools -- ways to do stuff\n",
    " - ### pipes -- ways to connect stuff together\n",
    " - ### devel tools -- ways to make your own tools and stuff\n",
    " - ### community -- ways to learn stuff and find friends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# ROS - Robot Operating System gives you:\n",
    "\n",
    " - ### tools -- ways to do stuff (motion, behaviours, drivers, intelligence ...)\n",
    " - ### pipes -- ways to connect stuff together (synchronous, asynchronous, data bases)\n",
    " - ### devel tools -- ways to make your own tools and stuff (simplified importing, packaging, building, sharing)\n",
    " - ### community -- ways to learn stuff and find friends (forums, books, university lectures ;))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ROS 2 ?\n",
    "\n",
    "Second iteration of the Framework\n",
    "\n",
    "Possible to make it (quite) safe -- good enough for Self Driving Cars\n",
    "\n",
    "Communication can be much faster \n",
    "\n",
    "Works not only on Linux â™¡ but also on MacOS and Windows, better on embedded devices\n",
    "\n",
    "Somewhat better organised, better programming practices\n",
    "\n",
    "Newer \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The main idea of ROS is to enable developers and makers:\n",
    "\n",
    "## you receive a universal system and build your dream robot on the top of it\n",
    "\n",
    "# You stand ot the shoulders of giants\n",
    "\n",
    "![standing on the shoulders of giants](images/standing-on-the-shoulders-of-giants.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# So how to start?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# I suggest:\n",
    "\n",
    " - ## Set the most interactive system possible\n",
    " - ## Work in simulations, understand tools one by one\n",
    " - ## Use ready-made tools and packages when possible\n",
    " - ## Even if you want to work on a big project, buy a toy robot to understand the problem\n",
    " - ## Use the forums, many issues are completely non-obvious and hard to isolate\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# This way you can start having fun first, worry later\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Ways of starting ROS 2 exploration:\n",
    "\n",
    "- [Native on Ubuntu, Windows, ChromeOS](https://index.ros.org/doc/ros2/Installation/)\n",
    "- VirtualBox [for example provided by MathWorks](https://www.mathworks.com/support/product/robotics/ros2-vm-installation-instructions-v3.html)\n",
    "- containerized (problematic starting of GUI applications)\n",
    "- containerized but with VNC accessible desktop environment (this is what I will be using during this presentation)\n",
    "\n",
    "A repo with dockerfiles and docker-compose files is available at https://github.com/AdoHaha/ros_fun.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "from IPython.display import display\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Using the repo container\n",
    "\n",
    "\n",
    "Clone the repository: `git clone https://github.com/AdoHaha/ros_fun.git`\n",
    "\n",
    "`cd ros_fun`\n",
    "\n",
    "Use `docker-compose up` to start the container. \n",
    "\n",
    "Navigate to: http://localhost:6080/\n",
    "from the host computer type:\n",
    "\n",
    "`docker container exec -it--user ubuntu ros_fun jupyter notebook --notebook-dir=\"./src/jupyter_notebooks\"\n",
    "`\n",
    "\n",
    "In different tab navigate http://localhost:8888"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Let's start running some robots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "By putting in two terminals (though novnc view):\n",
    "in one:\n",
    "\n",
    "`ros2 run turtlesim turtlesim_node`\n",
    "\n",
    "in second\n",
    "\n",
    "`ros2 run turtlesim turtle_teleop_key`\n",
    "\n",
    "you get turtle robot and a way to control it through keyboard.\n",
    "\n",
    "I will use a helper function to run it from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from run_lx import run_lxterminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "** (mate-terminal:1007): CRITICAL **: 17:26:22.951: terminal_window_remove_screen: assertion 'gtk_widget_get_toplevel (GTK_WIDGET (screen)) == GTK_WIDGET (window)' failed\n",
      "\n",
      "** (mate-terminal:1007): CRITICAL **: 17:26:24.142: terminal_window_remove_screen: assertion 'gtk_widget_get_toplevel (GTK_WIDGET (screen)) == GTK_WIDGET (window)' failed\n"
     ]
    }
   ],
   "source": [
    "run_lxterminal(\"ros2 run turtlesim turtlesim_node\")\n",
    "run_lxterminal(\"ros2 run turtlesim turtle_teleop_key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "We can play around by controling (teleoperating) robots with keyboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Obviously it is much more fun to control it from Python.\n",
    "To do this we need to create a **publisher** that publishes **twist**, that is 6 different parameters\n",
    "x,y,z velocity and\n",
    "yaw, pitch,roll rotational velocity\n",
    "\n",
    "![Yaw Pitch Roll](./images/yaw-pitch-roll.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Building a node with a publisher\n",
    "\n",
    "![Node, publisher subscriber](images/Nodes-TopicandService.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import rclpy\n",
    "from rclpy.node import Node\n",
    "\n",
    "\n",
    "from geometry_msgs.msg import Twist\n",
    "\n",
    "class TurtleMover(Node): #here we define new node\n",
    "\n",
    "    def __init__(self): \n",
    "        super().__init__('turtle_mover')\n",
    "        #we add publisher\n",
    "        self.publisher_ = self.create_publisher(Twist, \n",
    "                                                'turtle1/cmd_vel',\n",
    "                                                10)\n",
    "\n",
    "\n",
    "    def move_turtle(self,twist_command): #we add helper function\n",
    "        self.publisher_.publish(twist_command)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "rclpy.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "turtle_mover = TurtleMover()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the setup ready, we create a *message* object and fill the linear velocity x property\n",
    "\n",
    "We than publish to the turtle1/cmd_vel topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "twist_command = Twist()\n",
    "\n",
    "twist_command.linear.x = 1.0\n",
    "twist_command.angular.z = 1.0\n",
    "turtle_mover.move_turtle(twist_command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Using this we created our first **node** turtle_mover\n",
    "and connected it to a different node *turtlesim*\n",
    "\n",
    "We can see this using `rqt_graph` command in the terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "run_lxterminal(\"rqt_graph\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can send a series of messages to have particular robot behaviour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from types import MethodType\n",
    "\n",
    "move_front = Twist()\n",
    "move_front.linear.x = 1.0\n",
    "turn_right = Twist()\n",
    "turn_right.angular.z =1.0\n",
    "\n",
    "\n",
    "def make_shape(self):\n",
    "    if hasattr(self,\"n_moves\"):\n",
    "        self.n_moves+=1 \n",
    "    else: \n",
    "        self.n_moves= 1\n",
    "    if self.n_moves % 2 == 0:\n",
    "        \n",
    "        self.move_turtle(move_front)\n",
    "    else:\n",
    "        self.move_turtle(turn_right)\n",
    "\n",
    "turtle_mover.heart_move =  MethodType(make_shape,\n",
    "                                      turtle_mover) #create a new method for the node instance\n",
    "turtle_mover.timer = turtle_mover.create_timer(\n",
    "    1.0,\n",
    "    turtle_mover.heart_move)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Spinning\n",
    "\n",
    "We need to start spining to start receiving event calls -- such as timers or more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "rclpy.spin(turtle_mover) #start spinning the context\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "turtle_mover.timer.cancel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Subscribing to topics\n",
    "There is so much that you can do with robots without getting some feedback and sensory data. \n",
    "\n",
    "In ROS you usually do this by subscribing to topics.\n",
    "With our little turtle we can access its position. Let's start by reading it\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from turtlesim.msg import Pose\n",
    "\n",
    "def print_sensor_info_callback(self, msg):\n",
    "    print(msg)\n",
    "    \n",
    "turtle_mover.print_sensor_info_callback =  MethodType(\n",
    "    print_sensor_info_callback,\n",
    "    turtle_mover) #create a new method for the node instance\n",
    "turtle_mover.subscription = turtle_mover.create_subscription(\n",
    "    Pose,\n",
    "    \"turtle1/pose\", \n",
    "    turtle_mover.print_sensor_info_callback,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rclpy.spin(turtle_mover)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### That is a lot of information\n",
    "we can check how much by a ros2 tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "!ros2 topic hz /turtle1/pose\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "### We can use this information to make a wall avoiding robot\n",
    "\n",
    "#turtle_mover.subscription.destroy()\n",
    "turtle_mover.timer.cancel()\n",
    "\n",
    "def wall_avoider(self, msg):\n",
    "\n",
    "    wall_distance = 0.1\n",
    "    move_command = Twist()\n",
    "    move_command.linear.x = 1.0 # always ride front\n",
    "\n",
    "    if (msg.x > 10-wall_distance \n",
    "        or msg.x< wall_distance \n",
    "        or msg.y < wall_distance \n",
    "        or msg.y > 10 - wall_distance): #we are near wall\n",
    "        \n",
    "        move_command.linear.x = 2.0 # speed up\n",
    "        move_command.angular.z = 1.2 # add some rotation\n",
    "    self.publisher_.publish(move_command)\n",
    "    \n",
    "\n",
    "    \n",
    "turtle_mover.wall_avoider =  MethodType(wall_avoider, \n",
    "                                        turtle_mover) #create a new method for the node instance\n",
    "turtle_mover.subscription.callback =  turtle_mover.wall_avoider # change callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rclpy.spin(turtle_mover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#currentely a way to unsubscribe is a \"work in progress\" in ROS 2 so we just pass messages to function that does nothing\n",
    "def ignore_messages(msg):\n",
    "    pass\n",
    "turtle_mover.subscription.callback = ignore_messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Actions\n",
    "\n",
    "While fun,\n",
    "it would make sense to abstract some behaviours and just wait for some action result - success or failure\n",
    "\n",
    "This is what actions are for.\n",
    "\n",
    "![action idea](images/Action-SingleActionClient.gif)\n",
    "From:https://index.ros.org/doc/ros2/Tutorials/Understanding-ROS2-Actions/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from turtlesim.action import RotateAbsolute\n",
    "from rclpy.action import ActionClient\n",
    "\n",
    "easiest_action = ActionClient(turtle_mover,\n",
    "                              RotateAbsolute,\n",
    "                              'turtle1/rotate_absolute')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def deg2rad(deg):\n",
    "    return deg*math.pi/180\n",
    "\n",
    "angle_goal = RotateAbsolute.Goal()\n",
    "angle_goal.theta = deg2rad(45)\n",
    "\n",
    "easiest_action.send_goal_async(angle_goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def print_feedback(future):\n",
    "    \"\"\"callback that runs when robot\n",
    "    sends us feedback\"\"\"\n",
    "    try:\n",
    "        print(\"FEEDBACK: remaining radians {}\".format(\n",
    "            future.feedback.remaining))\n",
    "    except:\n",
    "        pass\n",
    "def received_task(future):\n",
    "    \"\"\"callback that runs when robot responds\"\"\"\n",
    "    goal_handle =  future.result()\n",
    "    \n",
    "    if not goal_handle.accepted:\n",
    "        print(\"not accepted\")\n",
    "        return\n",
    "    \n",
    "    get_result_future = goal_handle.get_result_async()\n",
    "    \n",
    "    get_result_future.add_done_callback(history_success)\n",
    "    \n",
    "def history_success(future):\n",
    "    \"\"\"callback that runs when robot finishes\"\"\"\n",
    "    print(\"done\")\n",
    "    print(\"radial distance was {}\".format(\n",
    "        future.result().result.delta))   \n",
    "    \n",
    "#ngle_goal.theta = math.pi/2\n",
    "angle_goal.theta = deg2rad(-90)\n",
    "#angle_goal.theta = 0.0\n",
    "\n",
    "goal_future = easiest_action.send_goal_async(\n",
    "    angle_goal,\n",
    "    feedback_callback = print_feedback)\n",
    "\n",
    "goal_future.add_done_callback(received_task)\n",
    "rclpy.spin(turtle_mover)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Services\n",
    "\n",
    "Most classic aproach, we send a request and receive response.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Services\n",
    "\n",
    "from turtlesim.srv import SetPen\n",
    "\n",
    "service_client = turtle_mover.create_client(SetPen,\"turtle1/set_pen\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "new_pen = SetPen.Request() \n",
    "\n",
    "new_pen.r = 255\n",
    "new_pen.width = 5 \n",
    "service_client.call_async(new_pen)\n",
    "\n",
    "\n",
    "turtle_mover.move_turtle(twist_command) #move to see effect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Congrats, you now used all types of ROS 2 communication.\n",
    "\n",
    "(with the exception of a parameter server ;))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "run_lxterminal(\"ros2 launch turtlebot3_gazebo turtlebot3_world.launch.py\")\n",
    "run_lxterminal(\"ros2 run turtlebot3_teleop teleop_keyboard\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "\n",
    "![Dissapointed robot](./images/dissapointed_robot.jpg)\n",
    "\n",
    "# What has this to do with serious robotics?\n",
    "\n",
    "\n",
    "Same type of communication is used while using \"normal\" robots. \n",
    "\n",
    "You usually look for the correct topics to subscribe\n",
    "and build your robot behaviours by connecting different nodes together.\n",
    "\n",
    "Instead of *turtlesim* let's use Turtlebot as an example ;)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In the same way as with the turtlesim you can send twist command to control this *real* robot.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "big_turtle_publisher = turtle_mover.create_publisher(\n",
    "    Twist,\n",
    "    'cmd_vel',\n",
    "    10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "new_msg =  Twist()\n",
    "\n",
    "#new_msg.linear.x = 0.3\n",
    "new_msg.angular.z = 0.1\n",
    "big_turtle_publisher.publish(new_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from cv_bridge import CvBridge\n",
    "import cv2\n",
    "from sensor_msgs.msg import CameraInfo, Image\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import IPython.display # import Image as , display\n",
    "from io import BytesIO\n",
    "import matplotlib as mpl\n",
    "\n",
    "\n",
    "def arr2img(arr):\n",
    "    \"\"\"Display a 2- or 3-d numpy array as an image.\"\"\"\n",
    "    if arr.ndim == 2:\n",
    "        format, cmap = 'png', mpl.cm.gray\n",
    "    elif arr.ndim == 3:\n",
    "        format, cmap = 'jpg', None\n",
    "    else:\n",
    "        raise ValueError(\"Only 2- or 3-d arrays can be displayed as images.\")\n",
    "    # Don't let matplotlib autoscale the color range so we can control overall luminosity\n",
    "    vmax = 255 if arr.dtype == 'uint8' else 1.0\n",
    "    with BytesIO() as buffer:\n",
    "        mpl.image.imsave(buffer, arr, format=format, cmap=cmap, vmin=0, vmax=vmax)\n",
    "        out = buffer.getvalue()\n",
    "    return IPython.display.Image(out)\n",
    "\n",
    "def camera_image_callback(rgb_msg):\n",
    "    \"show the camera image on the global dh display\"\n",
    "    rgb_image = CvBridge().imgmsg_to_cv2(rgb_msg, desired_encoding=\"rgb8\")\n",
    "\n",
    "    dh.update(arr2img(rgb_image))\n",
    "    \n",
    "    return arr2img(rgb_image)\n",
    "    \n",
    "\n",
    "#turtle_mover.image_subscription.callback = camera_image_callback\n",
    "turtle_mover.image_subscription = turtle_mover.create_subscription(Image,\n",
    "                                                                   \"/camera/image_raw\", \n",
    "                                                                   camera_image_callback,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "dh = IPython.display.display(display_id=True)\n",
    "dh.display(\"https://image.shutterstock.com/image-vector/example-red-square-grunge-stamp-260nw-327662909.jpg\")\n",
    "rclpy.spin(turtle_mover)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# You use actions for advanced behaviours\n",
    "\n",
    "Let's see how we can navigate the robot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run navigation and send actions\n",
    "\n",
    "run_lxterminal(\"ros2 launch turtlebot3_navigation2 navigation2.launch.py use_sim_time:=True map:=/home/ubuntu/turtlebot3_ws/src/jupyter_notebooks/map.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# First we need to send initial pose\n",
    "\n",
    "Using initialpose topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from geometry_msgs.msg import PoseWithCovarianceStamped\n",
    "\n",
    "send_start_pose_publisher = turtle_mover.create_publisher(PoseWithCovarianceStamped, 'initialpose', 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "initial_pose = PoseWithCovarianceStamped()\n",
    "initial_pose.header.stamp = turtle_mover.get_clock().now().to_msg()\n",
    "initial_pose.header.frame_id = \"map\"\n",
    "initial_pose.pose.pose.position.x = 0.08\n",
    "initial_pose.pose.pose.position.y = 0.0\n",
    "initial_pose.pose.pose.orientation.z = 0.0\n",
    "initial_pose.pose.pose.orientation.w = 1.0\n",
    "\n",
    "initial_pose.pose.covariance[0] = 0.25\n",
    "initial_pose.pose.covariance[7] = 0.25\n",
    "initial_pose.pose.covariance[-1] = 0.06\n",
    "\n",
    "send_start_pose_publisher.publish(initial_pose)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Now we can send the robot to any point on the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geometry_msgs.msg import PoseStamped\n",
    "\n",
    "send_goal_pose_publisher = turtle_mover.create_publisher(PoseStamped, '/move_base_simple/goal', 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_pose = PoseStamped()\n",
    "goal_pose.header.stamp = turtle_mover.get_clock().now().to_msg()\n",
    "goal_pose.pose.position.x = 3.8\n",
    "goal_pose.pose.position.y = 1.07\n",
    "goal_pose.pose.orientation.z = 0.7\n",
    "goal_pose.pose.orientation.w = 0.71\n",
    "\n",
    "send_goal_pose_publisher.publish(goal_pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from geometry_msgs.action import \n",
    "from nav2_msgs.action import NavigateToPose\n",
    "from rclpy.action import ActionClient\n",
    "from geometry_msgs.msg import PoseStamped\n",
    "\n",
    "navigate_action = ActionClient(\n",
    "    turtle_mover, \n",
    "    NavigateToPose,\n",
    "    '/navigate_to_pose')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# We can also receive feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def print_feedback_goal(future):\n",
    "    try:\n",
    "        print(\"feedback {}\".format(future.feedback))\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "def history_success(future):\n",
    "    print(\"done\")\n",
    "    print(\"we have achieved the goal {}, {}\".format(\n",
    "        future.result(),\n",
    "        future.result().result))\n",
    "    \n",
    "def received_task(future):\n",
    "    goal_handle =  future.result()\n",
    "    \n",
    "    if not goal_handle.accepted:\n",
    "        print(\"not accepted\")\n",
    "        return\n",
    "    else:\n",
    "        print(\"accepted goal\")\n",
    "    \n",
    "    get_result_future = goal_handle.get_result_async()\n",
    "    \n",
    "    get_result_future.add_done_callback(history_success)\n",
    "\n",
    "\n",
    "navigate_pose_goal = NavigateToPose.Goal()    \n",
    "goal_pose = PoseStamped()\n",
    "goal_pose.header.stamp = turtle_mover.get_clock().now().to_msg()\n",
    "goal_pose.pose.position.x = 4.0\n",
    "goal_pose.pose.position.y = 0.0\n",
    "goal_pose.pose.orientation.z = 0.7\n",
    "goal_pose.pose.orientation.w = 0.71\n",
    "navigate_pose_goal.pose = goal_pose\n",
    "goal_future_pose = navigate_action.send_goal_async(navigate_pose_goal,feedback_callback=print_feedback_goal)\n",
    "goal_future_pose.add_done_callback(received_task) \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Let's run with video feed ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh.display(\"https://image.shutterstock.com/image-vector/example-red-square-grunge-stamp-260nw-327662909.jpg\")\n",
    "\n",
    "rclpy.spin(turtle_mover)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Wrapup\n",
    "\n",
    "1. Robotics are fun but kind of complicated\n",
    "\n",
    "2. You can use great tools and other people's knowledge using ROS\n",
    "\n",
    "3. ROS 2 is easly accessable from Python and convenientely controllable from Jupyter\n",
    "\n",
    "\n",
    "I encourage you to play with ROS, spinning a container and starting Jupyter will take you just a minute\n",
    "\n",
    "If you are interested in programming robots for rehabilitation (as well as machine learning in retail) please contact me:\n",
    "\n",
    "twitter: @IgorZub \n",
    "igorzubrycki@gmail.com \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
